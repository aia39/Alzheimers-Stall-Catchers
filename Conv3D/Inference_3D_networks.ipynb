{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inference_3D_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMnMdYzYiThY",
        "colab_type": "text"
      },
      "source": [
        "# Test GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rftLe66DQIw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-woKEfviSEf",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2etPrrlvR4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ-FLOjvmgGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Folder => \"Alzheimer Competition\"\n",
        "https://drive.google.com/drive/folders/1-NIobsSrpU5JyUfu0bqbuWZU32GVZ7-m?usp=sharing\n",
        "\n",
        "Folder => \"SayeedColab\"\n",
        "https://drive.google.com/drive/folders/1wnL3y-kltnGwsV9dhha6BbOI7UwF0YJW?usp=sharing\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha8XOZ-9PYnS",
        "colab_type": "text"
      },
      "source": [
        "# Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiVLFMGkvWdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import h5py\n",
        "import csv\n",
        "\n",
        "# importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import time\n",
        "import glob\n",
        "import gc\n",
        "\n",
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import *\n",
        "import torch.utils.data\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHbVb8AXe09N",
        "colab_type": "text"
      },
      "source": [
        "**TIP:** This training could take several hours depending on how many iterations you chose in the .cfg file. You will want to let this run as you sleep or go to work for the day, etc. However, Colab Cloud Service kicks you off it's VMs if you are idle for too long (30-90 mins).\n",
        "\n",
        "To avoid this hold (CTRL + SHIFT + i) at the same time to open up the inspector view on your browser.\n",
        "\n",
        "Paste the following code into your console window and hit **Enter**\n",
        "```\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document\n",
        "  .querySelector('#top-toolbar > colab-connect-button')\n",
        "  .shadowRoot.querySelector('#connect')\n",
        "  .click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSE5uxfFPflT",
        "colab_type": "text"
      },
      "source": [
        "# Copy Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_jwU4Wva_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "\n",
        "shutil.copyfile(\"/content/drive/My Drive/AlzheimerStallCatcher3DConvPointCloud/resnet.py\", \"resnet.py\")\n",
        "shutil.copyfile(\"/content/drive/My Drive/Alzheimer Competition/submission_format.csv\", \"submission_format.csv\")\n",
        "\n",
        "\n",
        "submission_format_csv = \"submission_format.csv\"\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as-f0hnidHLb",
        "colab_type": "text"
      },
      "source": [
        "### RESNET101 Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TpKd0izZwzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"This section is going to take about 20 minutes time\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_1.zip\";\n",
        "print(\"partition 1 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_2.zip\";\n",
        "print(\"partition 2 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_3.zip\";\n",
        "print(\"partition 3 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_4.zip\";\n",
        "print(\"partition 4 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_5.zip\";\n",
        "print(\"partition 5 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_6.zip\";\n",
        "print(\"partition 6 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_7.zip\";\n",
        "print(\"partition 7 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_8.zip\";\n",
        "print(\"partition 8 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_9.zip\";\n",
        "print(\"partition 9 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_10.zip\";\n",
        "print(\"partition 10 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_11.zip\";\n",
        "print(\"partition 11 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_12.zip\";\n",
        "print(\"partition 12 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_13.zip\";\n",
        "print(\"partition 13 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_14.zip\";\n",
        "print(\"partition 14 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/test_15.zip\";\n",
        "print(\"partition 15 imported\")\n",
        "\n",
        "\n",
        "path = \"./test/\"\n",
        "files = [f for f in glob.glob(\"test/\" + \"*\" + \".pt\", recursive=True)]\n",
        "print(\"Total: \" + str(len(files)) + \" should be 14160\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRqt_1GtcoMD",
        "colab_type": "text"
      },
      "source": [
        "# Mandatory Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58VoWWG1cp9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string2torch(test_y):\n",
        "  df = pd.DataFrame(test_y, columns = ['Fname'])\n",
        "  y = (df['Fname'].values)\n",
        "\n",
        "  for i,filename in enumerate(y):\n",
        "    seq_name = filename.split(\".mp4\")[0]\n",
        "    y[i] = seq_name\n",
        "\n",
        "  processed = np.array(y)\n",
        "  processed = processed.astype(np.int)\n",
        "  processed = torch.from_numpy(processed)\n",
        "\n",
        "  return processed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHVrDSS5ctYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_submission_file(filenames, y_pred):\n",
        "  submit = []\n",
        "  filenames = filenames.astype(int)\n",
        "  for i in filenames:\n",
        "    submit += [str(i)+'.mp4']\n",
        "\n",
        "  submission_dict = {\"filename\": submit, \"stalled\": y_pred.astype(int)}\n",
        "  submission_csv = pd.DataFrame(submission_dict)\n",
        "  submission_csv.to_csv(\"submission3D.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFossLqLcwoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(submission_format_csv, mode='r') as infile:\n",
        "    reader = csv.reader(infile)\n",
        "    test_list_csv = {rows[0]: rows[1] for rows in reader}\n",
        "    infile.close()\n",
        "\n",
        "\n",
        "files = list(test_list_csv.keys())\n",
        "files.pop(0)\n",
        "test_len = len(files)\n",
        "print(\"Total data: \" + str(test_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro6BzS5XcBIF",
        "colab_type": "text"
      },
      "source": [
        "# RESNET101 Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GA31KI2cDMA",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkXmS_tacAYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "depth, height, width = 32, 64, 64   # dimension for converting point cloud to voxels\n",
        "\n",
        "shutil.copyfile(\"/content/drive/My Drive/Alzheimer Competition/lr1e-4_dec8e-4_90.484_mcc_0.766.pth\", \"weight_3D.pth\")\n",
        "checkpoint_model = \"weight_3D.pth\"\n",
        "\n",
        "# fold3_resnet101_aug16_32_64_64_acc_85.476_mcc_0.641.pth\n",
        "# lr1e-4_dec1e-3_acc_89.649_mcc_0.744.pth\n",
        "# lr1e-4_dec8e-4_90.484_mcc_0.766.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B_5QlrYcOhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import resnet\n",
        "model = resnet.resnet101(\n",
        "                num_classes=2,\n",
        "                shortcut_type='B',\n",
        "                sample_size=64,\n",
        "                sample_duration=32)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(checkpoint_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huyxjbv3bxkp",
        "colab_type": "text"
      },
      "source": [
        "### Resnet101 Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tTP9KlRbxEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []\n",
        "filenames = np.array([])\n",
        "\n",
        "\n",
        "big_batch_size = 1024   # number of test data loaded at a time\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "for big_batch_no in range(math.ceil(test_len/big_batch_size)):\n",
        "\n",
        "  this_batch_len = big_batch_size\n",
        "  if (test_len - big_batch_size * big_batch_no) < big_batch_size:\n",
        "    this_batch_len = test_len - big_batch_size * big_batch_no\n",
        "\n",
        "\n",
        "  test_x = np.zeros((this_batch_len, 3, depth, height, width), dtype=np.float32)\n",
        "  test_yy = np.zeros(this_batch_len)\n",
        "\n",
        "\n",
        "  # Load one big batch\n",
        "  for i in tqdm(range(this_batch_len)):\n",
        "\n",
        "    original_idx = i + big_batch_size * big_batch_no\n",
        "\n",
        "    f = files[original_idx]\n",
        "    original_name = f.replace(\".mp4\", \"\")\n",
        "\n",
        "    test_x[i, :, :, :, :] = torch.load(path + original_name + \".pt\")\n",
        "    test_yy[i] = int(original_name)\n",
        "\n",
        "    # print(original_idx, original_name, f, h5_filename)\n",
        "\n",
        "  \n",
        "  # Test one big batch\n",
        "  test_y = torch.from_numpy(test_yy).int()\n",
        "  ## change the data types from here\n",
        "  test_x = torch.from_numpy(test_x).float()\n",
        "  #test_y = torch.from_numpy(test_y)\n",
        "  \n",
        "  test = torch.utils.data.TensorDataset(test_x, test_y)\n",
        "  test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False, num_workers=4)\n",
        "\n",
        "  model.eval()\n",
        "  for i,(images,labels) in tqdm(enumerate(test_loader)):\n",
        "      #print(labels)\n",
        "      filenames = np.append(filenames, labels)\n",
        "      \n",
        "      images = images.view(-1,3,depth,height,width)\n",
        "      test = Variable(images.to(device), requires_grad=False)\n",
        "      labels = Variable(labels.to(device), requires_grad=False)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        # Forward propagation\n",
        "        outputs = model(test)\n",
        "\n",
        "        # Get predictions from the maximum value\n",
        "        predicted = torch.max(outputs.data, 1)[1]\n",
        "        #print(f\"prediction size are {predicted.shape}\")\n",
        "        y_pred = np.append(y_pred, predicted.cpu().numpy())\n",
        "\n",
        "#print(filenames)\n",
        "\n",
        "make_submission_file(filenames, y_pred)\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}