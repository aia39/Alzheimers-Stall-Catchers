{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inference_3D_norm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMnMdYzYiThY",
        "colab_type": "text"
      },
      "source": [
        "# Test GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rftLe66DQIw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-woKEfviSEf",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2etPrrlvR4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha8XOZ-9PYnS",
        "colab_type": "text"
      },
      "source": [
        "# Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiVLFMGkvWdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import h5py\n",
        "import csv\n",
        "\n",
        "# importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import time\n",
        "import glob\n",
        "import gc\n",
        "\n",
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import *\n",
        "import torch.utils.data\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSE5uxfFPflT",
        "colab_type": "text"
      },
      "source": [
        "# Copy Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_jwU4Wva_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.copyfile(\"/content/drive/My Drive/Alzheimer Competition/test_cloud.zip\" , \"test_cloud.zip\")\n",
        "shutil.copyfile(\"/content/drive/My Drive/Alzheimer Competition/submission_format.csv\", \"submission_format.csv\")\n",
        "\n",
        "!unzip test_cloud.zip;\n",
        "\n",
        "os.remove(\"test_cloud.zip\")\n",
        "\n",
        "path = \"./test_cloud/\"\n",
        "submission_format_csv = \"submission_format.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdYglf5ihyKJ",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muTW06MkPqh6",
        "colab_type": "text"
      },
      "source": [
        "### CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CDU5Wliv6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "depth, height, width = 32, 64, 64   # dimension for converting point cloud to voxels\n",
        "\n",
        "shutil.copyfile(\"/content/drive/My Drive/Alzheimer Competition/cloud_size_32_64_64_acc_81.198_mcc_0.515.pth\", \"weight_3D.pth\")\n",
        "checkpoint_model = \"weight_3D.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPZRD27rwIpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 2\n",
        "\n",
        "# Create CNN Model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        \n",
        "        self.conv_layer1 = self._conv_layer_set(3, 32)\n",
        "        self.conv_layer2 = self._conv_layer_set(32, 64)\n",
        "        self.fc1 = nn.Linear(75264, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 512)\n",
        "        self.fc3 = nn.Linear(512, 128)\n",
        "        self.fc4 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.batch1 = nn.BatchNorm1d(2048)\n",
        "        self.batch2 = nn.BatchNorm1d(512)\n",
        "        self.batch3 = nn.BatchNorm1d(128)\n",
        "        self.drop=nn.Dropout(p=0.5)        \n",
        "        \n",
        "    def _conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "        nn.Conv3d(in_c, out_c, kernel_size=(3, 3, 3), padding=0),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.MaxPool3d((2, 2, 2)),\n",
        "        )\n",
        "        return conv_layer\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        # Set 1\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.drop(out)\n",
        "        out = self.conv_layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        #print(out.shape)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.batch1(out)\n",
        "        out = self.drop(out)\n",
        "        \n",
        "        out = self.fc2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.batch2(out)\n",
        "        out = self.drop(out)\n",
        "\n",
        "        out = self.fc3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.batch3(out)\n",
        "        out = self.drop(out)\n",
        "        out = self.fc4(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "# Create CNN\n",
        "model = CNNModel()\n",
        "#model.cuda()\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "#device\n",
        "\n",
        "\n",
        "#loading saved weight file\n",
        "model.load_state_dict(torch.load(checkpoint_model))\n",
        "\n",
        "\n",
        "#device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgR7CWBtiBQY",
        "colab_type": "text"
      },
      "source": [
        "### Resnet3D  18 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fHYc7zXiEkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "depth, height, width = 32, 64, 64   # dimension for converting point cloud to voxels\n",
        "\n",
        "shutil.copyfile(\"/content/drive/My Drive/Alzheimer Competition/cloud_size_32_64_64_acc_81.198_mcc_0.515.pth\", \"weight_3D.pth\")\n",
        "checkpoint_model = \"weight_3D.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCO2wjTDh5RA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models.video import r3d_18\n",
        "#from torchvision.models.video import r2plus1d_18\n",
        "model = r3d_18(pretrained = False)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.fc.out_features = 2\n",
        "\n",
        "model.load_state_dict(torch.load(checkpoint_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKu09n_5PzEy",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9IlkuVWibKy",
        "colab_type": "text"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Um6m723PyP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pc2voxel(cloud0, cloud1, cloud2, depth=16, height=32, width=32):\n",
        "\n",
        "    voxel_grid = np.zeros((3, depth, height, width), dtype=np.float16)\n",
        "\n",
        "    in_depth = max(np.max(cloud0[:, 0]), np.max(cloud1[:, 0]), np.max(cloud2[:, 0]))\n",
        "    in_height = max(np.max(cloud0[:, 1]), np.max(cloud1[:, 1]), np.max(cloud2[:, 1]))\n",
        "    in_width = max(np.max(cloud0[:, 2]), np.max(cloud1[:, 2]), np.max(cloud2[:, 2]))\n",
        "\n",
        "    if in_depth >= depth:\n",
        "        depth_ratio = depth / (in_depth + 1)\n",
        "        cloud0[:, 0] = np.uint32(cloud0[:, 0].astype(float) * depth_ratio)\n",
        "        cloud1[:, 0] = np.uint32(cloud1[:, 0].astype(float) * depth_ratio)\n",
        "        cloud2[:, 0] = np.uint32(cloud2[:, 0].astype(float) * depth_ratio)\n",
        "    if in_height >= height:\n",
        "        height_ratio = height / (in_height + 1)\n",
        "        cloud0[:, 1] = np.uint32(cloud0[:, 1].astype(float) * height_ratio)\n",
        "        cloud1[:, 1] = np.uint32(cloud1[:, 1].astype(float) * height_ratio)\n",
        "        cloud2[:, 1] = np.uint32(cloud2[:, 1].astype(float) * height_ratio)\n",
        "    if in_width >= width:\n",
        "        width_ratio = width / (in_width + 1)\n",
        "        cloud0[:, 2] = np.uint32(cloud0[:, 2].astype(float) * width_ratio)\n",
        "        cloud1[:, 2] = np.uint32(cloud1[:, 2].astype(float) * width_ratio)\n",
        "        cloud2[:, 2] = np.uint32(cloud2[:, 2].astype(float) * width_ratio)\n",
        "\n",
        "    voxel_grid[0, cloud0[:, 0], cloud0[:, 1], cloud0[:, 2]] = 1.0\n",
        "    voxel_grid[1, cloud1[:, 0], cloud1[:, 1], cloud1[:, 2]] = 1.0\n",
        "    voxel_grid[2, cloud2[:, 0], cloud2[:, 1], cloud2[:, 2]] = 1.0\n",
        "\n",
        "    return voxel_grid"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBfUhKPCth6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string2torch(test_y):\n",
        "  df = pd.DataFrame(test_y, columns = ['Fname'])\n",
        "  y = (df['Fname'].values)\n",
        "\n",
        "  for i,filename in enumerate(y):\n",
        "    seq_name = filename.split(\".mp4\")[0]\n",
        "    y[i] = seq_name\n",
        "\n",
        "  processed = np.array(y)\n",
        "  processed = processed.astype(np.int)\n",
        "  processed = torch.from_numpy(processed)\n",
        "\n",
        "  return processed"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6wL_pUi865o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_submission_file(filenames, y_pred):\n",
        "  submit = []\n",
        "  filenames = filenames.astype(int)\n",
        "  for i in filenames:\n",
        "    submit += [str(i)+'.mp4']\n",
        "\n",
        "  submission_dict = {\"filename\": submit, \"stalled\": y_pred.astype(int)}\n",
        "  submission_csv = pd.DataFrame(submission_dict)\n",
        "  submission_csv.to_csv(\"submission3D.csv\", index=False)\n",
        "  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yB9E3sDP6wg",
        "colab_type": "text"
      },
      "source": [
        "### Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "798z-GIFP48S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(submission_format_csv, mode='r') as infile:\n",
        "    reader = csv.reader(infile)\n",
        "    test_list_csv = {rows[0]: rows[1] for rows in reader}\n",
        "    infile.close()\n",
        "\n",
        "\n",
        "files = list(test_list_csv.keys())\n",
        "files.pop(0)\n",
        "test_len = len(files)\n",
        "print(\"Total data: \" + str(test_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwRKoGlWQIVw",
        "colab_type": "text"
      },
      "source": [
        "# Prediction and Submission file generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBxzL8qtnuNo",
        "colab_type": "text"
      },
      "source": [
        "### CNN Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjZp_tpvwSKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []\n",
        "filenames = np.array([])\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "big_batch_size = 1000   # number of test data loaded at a time\n",
        "\n",
        "for big_batch_no in range(math.ceil(test_len/big_batch_size)):\n",
        "\n",
        "  this_batch_len = big_batch_size\n",
        "  if (test_len - big_batch_size * big_batch_no) < big_batch_size:\n",
        "    this_batch_len = test_len - big_batch_size * big_batch_no\n",
        "\n",
        "\n",
        "  test_x = np.zeros((this_batch_len, 3, depth, height, width), dtype=np.float32)\n",
        "  test_yy = np.zeros(this_batch_len)\n",
        "\n",
        "\n",
        "  # Load one big batch\n",
        "  for i in range(this_batch_len):\n",
        "\n",
        "    original_idx = i + big_batch_size * big_batch_no\n",
        "\n",
        "    f = files[original_idx]\n",
        "    original_name = f.replace(\".mp4\", \"\")\n",
        "    h5_filename = path + original_name + \".h5\"\n",
        "\n",
        "    hf = h5py.File(h5_filename, 'r')\n",
        "    c1 = hf['cloud1'][:]\n",
        "    c2 = hf['cloud2'][:]\n",
        "    c3 = hf['cloud3'][:]\n",
        "    hf.close()\n",
        "\n",
        "\n",
        "    test_x[i, :, :, :, :] = pc2voxel(c1, c2, c3, depth=depth, height=height, width=width)\n",
        "    test_yy[i] = int(original_name)\n",
        "    # print(original_idx, original_name, f, h5_filename)\n",
        "\n",
        "  \n",
        "  # Test one big batch\n",
        "  test_y = torch.from_numpy(test_yy).int()\n",
        "  ## change the data types from here\n",
        "  test_x = torch.from_numpy(test_x).float()\n",
        "  #test_y = torch.from_numpy(test_y)\n",
        "  \n",
        "  test = torch.utils.data.TensorDataset(test_x, test_y)\n",
        "  test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False, num_workers=4)\n",
        "\n",
        "  model.eval()\n",
        "  for i,(images,labels) in tqdm(enumerate(test_loader)):\n",
        "      print(labels)\n",
        "      filenames = np.append(filenames, labels)\n",
        "      \n",
        "      images = images.view(-1,3,depth,height,width)\n",
        "      test = Variable(images.to(device), requires_grad=False)\n",
        "      labels = Variable(labels.to(device), requires_grad=False)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        # Forward propagation\n",
        "        outputs = model(test)\n",
        "\n",
        "        # Get predictions from the maximum value\n",
        "        predicted = torch.max(outputs.data, 1)[1]\n",
        "        #print(f\"prediction size are {predicted.shape}\")\n",
        "        y_pred = np.append(y_pred, predicted.cpu().numpy())\n",
        "\n",
        "#print(filenames)\n",
        "\n",
        "make_submission_file(filenames, y_pred)\n",
        "'''\n",
        "submission_dict = {\"filename\": filenames, \"stalled\": y_pred.astype(int)}\n",
        "\n",
        "submission_csv = pd.DataFrame(submission_dict)\n",
        "\n",
        "submission_csv.to_csv(\"submission_file.csv\", index=False)\n",
        "''' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rKeNqX1nruS",
        "colab_type": "text"
      },
      "source": [
        "### Resnet3D 18 Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGMRKLGunqiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []\n",
        "filenames = np.array([])\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "big_batch_size = 10   # number of test data loaded at a time\n",
        "\n",
        "for big_batch_no in range(math.ceil(test_len/big_batch_size)):\n",
        "\n",
        "  this_batch_len = big_batch_size\n",
        "  if (test_len - big_batch_size * big_batch_no) < big_batch_size:\n",
        "    this_batch_len = test_len - big_batch_size * big_batch_no\n",
        "\n",
        "\n",
        "  test_x = np.zeros((this_batch_len, 3, depth, height, width), dtype=np.float32)\n",
        "  test_yy = np.zeros(this_batch_len)\n",
        "\n",
        "\n",
        "  # Load one big batch\n",
        "  for i in tqdm(range(this_batch_len)):\n",
        "\n",
        "    original_idx = i + big_batch_size * big_batch_no\n",
        "\n",
        "    f = files[original_idx]\n",
        "    original_name = f.replace(\".mp4\", \"\")\n",
        "    h5_filename = path + original_name + \".h5\"\n",
        "\n",
        "    hf = h5py.File(h5_filename, 'r')\n",
        "    c1 = hf['cloud1'][:]\n",
        "    c2 = hf['cloud2'][:]\n",
        "    c3 = hf['cloud3'][:]\n",
        "    hf.close()\n",
        "\n",
        "\n",
        "    test_x[i, :, :, :, :] = pc2voxel(c1, c2, c3, depth=depth, height=height, width=width)\n",
        "    test_yy[i] = int(original_name)\n",
        "\n",
        "    # print(original_idx, original_name, f, h5_filename)\n",
        "\n",
        "  \n",
        "  # Test one big batch\n",
        "  test_y = torch.from_numpy(test_yy).int()\n",
        "  ## change the data types from here\n",
        "  test_x = torch.from_numpy(test_x).float()\n",
        "  #test_y = torch.from_numpy(test_y)\n",
        "  \n",
        "  test = torch.utils.data.TensorDataset(test_x, test_y)\n",
        "  test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False, num_workers=4)\n",
        "\n",
        "  model.eval()\n",
        "  for i,(images,labels) in tqdm(enumerate(test_loader)):\n",
        "      #print(labels)\n",
        "      filenames = np.append(filenames, labels)\n",
        "      \n",
        "      images = images.view(-1,3,depth,height,width)\n",
        "      test = Variable(images.to(device), requires_grad=False)\n",
        "      labels = Variable(labels.to(device), requires_grad=False)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        # Forward propagation\n",
        "        outputs = model(test)\n",
        "\n",
        "        # Get predictions from the maximum value\n",
        "        predicted = torch.max(outputs.data, 1)[1]\n",
        "        #print(f\"prediction size are {predicted.shape}\")\n",
        "        y_pred = np.append(y_pred, predicted.cpu().numpy())\n",
        "\n",
        "#print(filenames)\n",
        "\n",
        "make_submission_file(filenames, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}