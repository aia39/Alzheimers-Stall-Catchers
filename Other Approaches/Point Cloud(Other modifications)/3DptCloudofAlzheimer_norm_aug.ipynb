{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "3DptCloudofAlzheimer_norm_aug.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJBQPKTeJM2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG067iUUQPeR",
        "colab_type": "text"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok8yK4RbDFNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Uh_vIJQZzs",
        "colab_type": "text"
      },
      "source": [
        "# Copy Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWwCqwra84SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "shutil.copyfile('/content/drive/My Drive/Alzheimer Competition/point_cloud.zip' , './data/point_cloud.zip')\n",
        "shutil.copyfile('/content/drive/My Drive/Alzheimer Competition/traintestlist.zip' , './data/traintestlist.zip')\n",
        "\n",
        "!unzip data/point_cloud.zip;\n",
        "!unzip data/traintestlist.zip;\n",
        "\n",
        "os.remove(\"./data/point_cloud.zip\")\n",
        "os.remove('./data/traintestlist.zip')\n",
        "\n",
        "shutil.move('./point_cloud', './data/point_cloud')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWfvjBHvQLLb",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqOgAV40C5DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import glob\n",
        "import gc\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef as mcc\n",
        "\n",
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "from torchvision.models.video import r3d_18\n",
        "\n",
        "torch.manual_seed(100)\n",
        "\n",
        "import csv\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "MCC_SCORE = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEau83HIC5Dj",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWjtb3jFxUli",
        "colab_type": "text"
      },
      "source": [
        "### Save point cloud as voxel tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQFDF7F5l2CF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "class VoxelTensor:\n",
        "    def __init__(self, src_path):\n",
        "        self.data = \"\"\n",
        "        self.path = src_path\n",
        "\n",
        "    def pc2voxel(self, cloud0, cloud1, cloud2, depth=16, height=32, width=32, rotation=0):\n",
        "\n",
        "        voxel_grid = np.zeros((3, depth, height, width), dtype=np.float16)\n",
        "\n",
        "        in_depth = max(np.max(cloud0[:, 0]), np.max(cloud1[:, 0]), np.max(cloud2[:, 0]))\n",
        "        in_height = max(np.max(cloud0[:, 1]), np.max(cloud1[:, 1]), np.max(cloud2[:, 1]))\n",
        "        in_width = max(np.max(cloud0[:, 2]), np.max(cloud1[:, 2]), np.max(cloud2[:, 2]))\n",
        "\n",
        "        if in_depth >= depth:\n",
        "            depth_ratio = depth / (in_depth + 1)\n",
        "            cloud0[:, 0] = np.uint32(cloud0[:, 0].astype(float) * depth_ratio)\n",
        "            cloud1[:, 0] = np.uint32(cloud1[:, 0].astype(float) * depth_ratio)\n",
        "            cloud2[:, 0] = np.uint32(cloud2[:, 0].astype(float) * depth_ratio)\n",
        "        if in_height >= height:\n",
        "            height_ratio = height / (in_height + 1)\n",
        "            cloud0[:, 1] = np.uint32(cloud0[:, 1].astype(float) * height_ratio)\n",
        "            cloud1[:, 1] = np.uint32(cloud1[:, 1].astype(float) * height_ratio)\n",
        "            cloud2[:, 1] = np.uint32(cloud2[:, 1].astype(float) * height_ratio)\n",
        "        if in_width >= width:\n",
        "            width_ratio = width / (in_width + 1)\n",
        "            cloud0[:, 2] = np.uint32(cloud0[:, 2].astype(float) * width_ratio)\n",
        "            cloud1[:, 2] = np.uint32(cloud1[:, 2].astype(float) * width_ratio)\n",
        "            cloud2[:, 2] = np.uint32(cloud2[:, 2].astype(float) * width_ratio)\n",
        "\n",
        "\n",
        "        if rotation == 1:\n",
        "            y0, y1, y2 = cloud0[:, 1], cloud1[:, 1], cloud2[:, 1]\n",
        "            cloud0[:, 1] = cloud0[:, 2]\n",
        "            cloud1[:, 1] = cloud1[:, 2]\n",
        "            cloud2[:, 1] = cloud2[:, 2]\n",
        "            cloud0[:, 2] = in_height - y0\n",
        "            cloud1[:, 2] = in_height - y1\n",
        "            cloud2[:, 2] = in_height - y2\n",
        "        if rotation == 2:\n",
        "            cloud0[:, 1] = in_height - cloud0[:, 1]\n",
        "            cloud1[:, 1] = in_height - cloud1[:, 1]\n",
        "            cloud2[:, 1] = in_height - cloud2[:, 1]\n",
        "            cloud0[:, 2] = in_width - cloud0[:, 2]\n",
        "            cloud1[:, 2] = in_width - cloud1[:, 2]\n",
        "            cloud2[:, 2] = in_width - cloud2[:, 2]\n",
        "        if rotation == 3:\n",
        "            x0, x1, x2 = cloud0[:, 2], cloud1[:, 2], cloud2[:, 2]\n",
        "            cloud0[:, 2] = cloud0[:, 1]\n",
        "            cloud1[:, 2] = cloud1[:, 1]\n",
        "            cloud2[:, 2] = cloud2[:, 1]\n",
        "            cloud0[:, 1] = in_width - x0\n",
        "            cloud1[:, 1] = in_width - x1\n",
        "            cloud2[:, 1] = in_width - x2\n",
        "\n",
        "        voxel_grid[0, cloud0[:, 0], cloud0[:, 1], cloud0[:, 2]] = 1.0\n",
        "        voxel_grid[1, cloud1[:, 0], cloud1[:, 1], cloud1[:, 2]] = 1.0\n",
        "        voxel_grid[2, cloud2[:, 0], cloud2[:, 1], cloud2[:, 2]] = 1.0\n",
        "\n",
        "        return voxel_grid\n",
        "\n",
        "    def save(self, files_list, dst_path, dim, augment=False):\n",
        "        list_IDs = list(files_list.keys())\n",
        "        files_list_aug = {}\n",
        "        depth = dim[0]\n",
        "        height = dim[1]\n",
        "        width = dim[2]\n",
        "\n",
        "        os.makedirs(dst_path, exist_ok=True)\n",
        "\n",
        "        for ID in tqdm(list_IDs):\n",
        "            original_name = ID.replace(\".mp4\", \"\")\n",
        "            f = self.path + original_name + \".h5\"\n",
        "\n",
        "            hf = h5py.File(f, 'r')\n",
        "            c1 = hf['cloud1'][:]\n",
        "            c2 = hf['cloud2'][:]\n",
        "            c3 = hf['cloud3'][:]\n",
        "            hf.close()\n",
        "\n",
        "            y = files_list[ID]\n",
        "\n",
        "            if augment == False:\n",
        "              f_out = dst_path + original_name + \".pt\"\n",
        "              X = self.pc2voxel(c1, c2, c3, depth=depth, height=height, width=width)\n",
        "              X = torch.from_numpy(X).float()\n",
        "              torch.save(X, f_out)\n",
        "\n",
        "            else:\n",
        "              for rotation in range(4):\n",
        "                f_out = dst_path + original_name + str(rotation) + \".pt\"\n",
        "                aug_ID = original_name + str(rotation) + \".mp4\"\n",
        "                X = self.pc2voxel(c1, c2, c3, depth=depth, height=height, width=width, rotation=rotation)\n",
        "                X = torch.from_numpy(X).float()\n",
        "                files_list_aug[aug_ID] = y\n",
        "                torch.save(X, f_out)\n",
        "\n",
        "\n",
        "        if augment == False:\n",
        "          return files_list\n",
        "        else:\n",
        "          return files_list_aug\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8c05JU4xmkQ",
        "colab_type": "text"
      },
      "source": [
        "### Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmJqzMzjp3qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "class VoxelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, files_list, source_path):\n",
        "        self.list_IDs = list(files_list.keys())\n",
        "        self.labels = files_list\n",
        "        self.path = source_path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_IDs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ID = self.list_IDs[index]\n",
        "        original_name = ID.replace(\".mp4\", \"\")\n",
        "        f = self.path + original_name + \".pt\"\n",
        "\n",
        "        X = torch.load(f)\n",
        "\n",
        "        y = self.labels[ID]\n",
        "        y = torch.tensor(int(y))\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMEDRVRQxshP",
        "colab_type": "text"
      },
      "source": [
        "### Balanced Batch Sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMP7nk43xKJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torch.utils.data\n",
        "import random\n",
        "\n",
        "\n",
        "class BalancedBatchSampler(torch.utils.data.sampler.Sampler):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = {}\n",
        "        self.balanced_max = 0\n",
        "        # Save all the indices for all the classes\n",
        "        for idx in range(0, len(dataset)):\n",
        "            label = self._get_label(dataset, idx)\n",
        "            if label not in self.dataset:\n",
        "                self.dataset[label] = []\n",
        "            self.dataset[label].append(idx)\n",
        "            self.balanced_max = len(self.dataset[label]) \\\n",
        "                if len(self.dataset[label]) > self.balanced_max else self.balanced_max\n",
        "        \n",
        "        # Oversample the classes with fewer elements than the max\n",
        "        for label in self.dataset:\n",
        "            while len(self.dataset[label]) < self.balanced_max:\n",
        "                self.dataset[label].append(random.choice(self.dataset[label]))\n",
        "    \n",
        "        self.keys = list(self.dataset.keys())\n",
        "        self.currentkey = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        while len(self.dataset[self.keys[self.currentkey]]) > 0:\n",
        "            yield self.dataset[self.keys[self.currentkey]].pop()\n",
        "            self.currentkey = (self.currentkey + 1) % len(self.keys)\n",
        "\n",
        "    \n",
        "    def _get_label(self, dataset, idx):\n",
        "        dataset_type = type(dataset)\n",
        "        if dataset_type is torchvision.datasets.MNIST:\n",
        "            return dataset.train_labels[idx].item()\n",
        "        elif dataset_type is torchvision.datasets.ImageFolder:\n",
        "            return dataset.imgs[idx][1]\n",
        "        else:\n",
        "            (image_sequence, target) = dataset.__getitem__(idx)\n",
        "            return target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.balanced_max*len(self.keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrHYWRdRylC9",
        "colab_type": "text"
      },
      "source": [
        "### Point cloud files, train list, test list, generate tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ycvDU5oykKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fold_name = \"fold_0\"    # specify which train-test split to work with\n",
        "\n",
        "depth, height, width = 32, 64, 64   # dimension for converting point cloud to voxels\n",
        "\n",
        "\n",
        "dimension = [depth, height, width]\n",
        "\n",
        "# Point cloud files\n",
        "pc_path = \"./data/point_cloud/\"\n",
        "files = [f for f in glob.glob(pc_path + \"*.h5\", recursive=True)]\n",
        "\n",
        "# Train test list and labels\n",
        "train_labels_file = \"traintestlist/\" + fold_name + \"_train.csv\"\n",
        "test_labels_file = \"traintestlist/\" + fold_name + \"_test.csv\"\n",
        "\n",
        "train_files_directory = \"./dataset/train/\"\n",
        "test_files_directory = \"./dataset/test/\"\n",
        "\n",
        "\n",
        "\n",
        "with open(train_labels_file, mode='r') as infile:\n",
        "    reader = csv.reader(infile)\n",
        "    train_list = {rows[0]: rows[1] for rows in reader}\n",
        "    infile.close()\n",
        "train_list.pop(\"filename\", None)\n",
        "\n",
        "with open(test_labels_file, mode='r') as infile:\n",
        "    reader = csv.reader(infile)\n",
        "    test_list = {rows[0]: rows[1] for rows in reader}\n",
        "    infile.close()\n",
        "test_list.pop(\"filename\", None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkpyM-zVgcK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_list = VoxelTensor(pc_path).save(files_list=train_list, dst_path=train_files_directory, dim=dimension, augment=True)\n",
        "test_list = VoxelTensor(pc_path).save(files_list=test_list, dst_path=test_files_directory, dim=dimension)\n",
        "\n",
        "train_len, test_len = len(train_list), len(test_list)\n",
        "print(\"Train length: \" + str(train_len) + \" Test Length: \" + str(test_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aniT4teLxwnh",
        "colab_type": "text"
      },
      "source": [
        "### Create Train and Test Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAWM0douHdm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train = VoxelDataset(files_list=train_list, source_path=train_files_directory)\n",
        "#train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "train_loader = torch.utils.data.DataLoader(train,sampler=BalancedBatchSampler(train), batch_size = batch_size, num_workers=4)\n",
        "\n",
        "test = VoxelDataset(files_list=test_list, source_path=test_files_directory)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "print(\"Number of Batches: \" + str(len(train_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSzI-gKJC5D2",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "165yljYzrzN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.copyfile(\"/content/drive/My Drive/Alzheimer Competition/3D_pointcloud_SimpleCNN_10for_cloud_size_32_64_64_acc_79.534_mcc_0.465.pth\", \"weight_3D.pth\")\n",
        "checkpoint_model = \"weight_3D.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI0IKKUVP_22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models.video import r3d_18\n",
        "#from torchvision.models.video import r2plus1d_18\n",
        "#from torchvision.models.video import mc3_18\n",
        "\n",
        "model = r3d_18(pretrained = True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.fc.out_features = 2\n",
        "\n",
        "# model.load_state_dict(torch.load(checkpoint_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuwWzMuOuB6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model Hyperparameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "error = nn.CrossEntropyLoss().to(device)   #to use model on gpu\n",
        "\n",
        "#error = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "num_epochs = 100\n",
        "# Optimizer\n",
        "learning_rate = 1e-3\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)  #added L2 regularization\n",
        "# model\n",
        "\n",
        "\n",
        "n_iters = 1000\n",
        "num_epochss = n_iters / (train_len/ batch_size)\n",
        "num_epochss = int(num_epochs)\n",
        "print(\"Total Epochs: \" + str(num_epochss))\n",
        "print(\"Train Instances: \" + str(train_len))\n",
        "print(\"Batch Size: \" + str(batch_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx4e-KlLzBza",
        "colab_type": "text"
      },
      "source": [
        "# Visualization and Saving Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNcBjSDXrvbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conf_mat(cf, epoch, acc, mcc, y_true, train_loss, train_acc, test_loss, test_acc):\n",
        "  try:\n",
        "    plt.imshow(cf,cmap=plt.cm.RdYlGn,interpolation='nearest')\n",
        "    plt.colorbar()\n",
        "    plt.title('Confusion Matrix without Normalization')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    tick_marks = np.arange(len(set(y_true))) # length of classes\n",
        "    class_labels = ['Non Stalled','Stalled']\n",
        "    tick_marks\n",
        "    plt.xticks(tick_marks,class_labels)\n",
        "    plt.yticks(tick_marks,class_labels)\n",
        "    # plotting text value inside cells\n",
        "    thresh = cf.max() / 2.\n",
        "    for i,j in itertools.product(range(cf.shape[0]),range(cf.shape[1])):\n",
        "        plt.text(j,i,format(cf[i,j],'d'),horizontalalignment='center',color='white' if cf[i,j] >thresh else 'black')\n",
        "    #plt.show()\n",
        "    os.makedirs(\"confusion_matrix\", exist_ok=True)\n",
        "    plt.savefig(f\"confusion_matrix/epoch{epoch}_accuracy{round(acc.item(),3)}_mcc_{round(mcc.item(),3)}.png\")\n",
        "    plt.close('all')\n",
        "\n",
        "    os.makedirs(\"loss_acc_curve\", exist_ok=True)\n",
        "\n",
        "    ##creating subplot for loss,acc\n",
        "    fig1, axs = plt.subplots(4,sharex=True,constrained_layout=True)\n",
        "    axs[0].plot(train_loss, color = \"red\") \n",
        "    axs[0].set_title(\"Train loss\")\n",
        "    axs[1].plot(train_acc, color = \"blue\") \n",
        "    axs[1].set_title(\"Train Accuracy\")\n",
        "    axs[2].plot(test_loss, color = \"green\")\n",
        "    axs[2].set_title(\"Test Loss\")\n",
        "    axs[3].plot(test_acc) \n",
        "    axs[3].set_title(\"Test Accuracy\")\n",
        "    #fig1.tight_layout()\n",
        "    #plt.show()\n",
        "    fig1.savefig(f\"loss_acc_curve/epoch{epoch}_accuracy{round(acc.item(),3)}_mcc_{round(mcc.item(),3)}.png\")\n",
        "    plt.close(fig1)\n",
        "  except:\n",
        "    print(\"MCC is 0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4getcCEuOjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for cross entropy loss\n",
        "def validation(epoch,train_loss, train_acc, test_loss, test_acc):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  t_loss = 0\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "  # Iterate through test dataset\n",
        "  model.eval()\n",
        "  for images, labels in test_loader:\n",
        "      #print(f\"labels size are {labels.shape}\")\n",
        "      y_true = np.append(y_true, labels.numpy())\n",
        "      images = images.view(-1,3,depth,height,width)\n",
        "      test = Variable(images.to(device), requires_grad=False)\n",
        "      labels = Variable(labels.to(device), requires_grad=False)\n",
        "      with torch.no_grad():\n",
        "        # Forward propagation\n",
        "        outputs = model(test)\n",
        "        t_loss += error(outputs, labels)\n",
        "        # Get predictions from the maximum value\n",
        "        predicted = torch.max(outputs.data, 1)[1]\n",
        "        #print(f\"prediction size are {predicted.shape}\")\n",
        "        y_pred = np.append(y_pred, predicted.cpu().numpy())\n",
        "        # Total number of labels\n",
        "        total += len(labels)\n",
        "        correct += (predicted == labels).sum()\n",
        "  model.train()\n",
        "  loss = t_loss.cpu().numpy() / float(total)\n",
        "  test_loss.append(loss)\n",
        "  accuracy = 100 * correct / float(total)\n",
        "  test_acc.append(accuracy)\n",
        "\n",
        "  mcc_score = mcc(y_true, y_pred)\n",
        "  print(f\"MCC score is {round(mcc_score,4)}\")\n",
        "\n",
        "\n",
        "  global MCC_SCORE\n",
        "  if MCC_SCORE < mcc_score:\n",
        "      MCC_SCORE = mcc_score\n",
        "      os.makedirs(\"model_checkpoints\", exist_ok=True)\n",
        "      try:\n",
        "        torch.save(model.state_dict(), f\"model_checkpoints/3D_pointcloud_SimpleCNN_{epoch}for_cloud_size_32_64_64_acc_{round(accuracy.item(),3)}_mcc_{round(mcc_score.item(),3)}.pth\")\n",
        "      except:\n",
        "        pass\n",
        "  cf =confusion_matrix(y_true, y_pred)\n",
        "  #print(cf)\n",
        "  conf_mat(cf, epoch, accuracy, mcc_score, y_true, train_loss, train_acc, test_loss, test_acc)\n",
        "\n",
        "  print('TESTING ---> Epoch: {} Loss: {} Accuracy: {} %'.format(epoch, round(loss,3), round(accuracy.item(),3)))\n",
        "\n",
        "\n",
        "  return test_loss, test_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ddJpxiHvjiu",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRbHWrT1C5Ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TRAINING code\n",
        "import gc\n",
        "\n",
        "train_loss = []   #to keep track of loss with respect to number of epoch \n",
        "test_loss = []\n",
        "iteration_list = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    #count = 1\n",
        "    accuracy_list = []\n",
        "    loss_list = []\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        correct = 0\n",
        "        #print(images.shape)\n",
        "        images = images.view(-1,3,depth,height,width)\n",
        "        #train = Variable(images)    #to use on cpu\n",
        "        #labels = Variable(labels)    #to use on cpu\n",
        "\n",
        "        train_img = Variable(images.to(device), requires_grad=True)\n",
        "        labels = Variable(labels.to(device), requires_grad=False)\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Forward propagation\n",
        "        outputs = model(train_img)\n",
        "        # Calculate softmax and ross entropy loss\n",
        "        loss = error(outputs, labels)\n",
        "        \n",
        "        #labels = labels.view(-1, 1)  #only for BCELogitsloss\n",
        "        #loss = error(outputs.float(), labels.float())  #if BCELoss is measured\n",
        "        \n",
        "        # Calculating gradients\n",
        "        loss.backward()\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        predicted = torch.max(outputs.data, 1)[1]   \n",
        "        correct = (predicted == labels).sum()\n",
        "        total = len(labels)        \n",
        "        accuracy = 100 * correct / float(total)\n",
        "\n",
        "        '''\n",
        "        ###For BCELoss\n",
        "        predicted = torch.tensor([0 if i<=0.5 else 1 for i in outputs]).to(device)\n",
        "        accuracy = 100 * (predicted.detach() == labels).cpu().numpy().mean()\n",
        "        '''\n",
        "        #accuracy_list = np.append(accuracy_list, accuracy)\n",
        "\n",
        "        accuracy_list = np.append(accuracy_list, accuracy.cpu().numpy())\n",
        "        loss_list = np.append(loss_list, loss.detach().cpu().numpy())\n",
        "        #print(f\"Training Mini Batch--> Epoch:{epoch} Iteration:{count} Loss :{loss} Accuracy: {accuracy}\")\n",
        "        #count += 1\n",
        "    final_loss = np.mean(loss_list)\n",
        "    final_acc = np.mean(accuracy_list)\n",
        "    print(f\"TRAINING ---> Epoch: {epoch} Loss: {round(final_loss,4)} Accuracy: {round(final_acc,4)}\")\n",
        "    train_loss.append(final_loss)\n",
        "    train_acc.append(final_acc)\n",
        "    del loss_list, accuracy_list, labels\n",
        "    del predicted\n",
        "    del loss , outputs\n",
        "    del images\n",
        "    del train_img\n",
        "    gc.collect() \n",
        "    test_loss , test_acc = validation(epoch, train_loss, train_acc, test_loss, test_acc)\n",
        "    \n",
        "    train = VoxelDataset(files_list=train_list, source_path=train_files_directory)\n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    #train_loader = torch.utils.data.DataLoader(train,sampler=BalancedBatchSampler(train), batch_size = batch_size, num_workers=4)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSKe0us1Gi_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss.data\n",
        "#round(accuracy.data, 3)\n",
        "#np.mean(accuracy_list)\n",
        "mcc_score = mcc(y_true, y_pred)\n",
        "#print(len(y_true))\n",
        "#print(len(y_pred))\n",
        "len(accuracy_list)\n",
        "round(final_acc,4)\n",
        "print(mcc_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UGRrUzZC5Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# visualization loss \n",
        "plt.plot(train_loss)\n",
        "plt.xlabel(\"Number of iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"CNN: Loss vs Number of iteration\")\n",
        "plt.show()\n",
        "\n",
        "# visualization accuracy \n",
        "plt.plot(train_acc,color = \"red\")\n",
        "plt.xlabel(\"Number of iteration\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"CNN: Accuracy vs Number of iteration\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}